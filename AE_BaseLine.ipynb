{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_BaseLine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Aspect Extraction Baseline with Handcrafted features**"
      ],
      "metadata": {
        "id": "iOCNSwgfLR_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSAZfvj_U_Ng",
        "outputId": "fa6baa21-1728-4d80-9d0b-86edfdfb14d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download some libraries"
      ],
      "metadata": {
        "id": "oeTxpoNZLvOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "HqyuZfSNaYir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ahpprkaGkkf",
        "outputId": "6ba77782-5f95-461c-bd02-e58f133a016b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.64.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn_crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1kxwh5lJdSu",
        "outputId": "ba2ace81-1aee-4da7-96b7-8ce294598f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make the necessary imports"
      ],
      "metadata": {
        "id": "yEtbFMSeLOMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "from sklearn_crfsuite import CRF, metrics\n",
        "from sklearn.metrics import make_scorer,confusion_matrix\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import f1_score,classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "uCI7wQmEJdyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the training/testing data. \n",
        "\n",
        "**input**: Iob format data, but with only one space separated colums - words and NEtags.\n",
        "\n",
        "**output**: A list where each item is 2 lists.  sentence as a list of tokens, Aspect tags as a list for each token."
      ],
      "metadata": {
        "id": "AYv9v1KQKHAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load__data_conll(file_path):\n",
        "    myoutput,words,tags = [],[],[]\n",
        "    fh = open(file_path)\n",
        "    for line in fh:\n",
        "        line = line.strip()\n",
        "        #print(line)\n",
        "        if line=='':\n",
        "            #Sentence ended.\n",
        "            #print(\"-----------------------------\")\n",
        "            myoutput.append([words,tags])\n",
        "            words,tags = [],[]\n",
        "        else:\n",
        "            word, tag = line.split()\n",
        "            words.append(word)\n",
        "            tags.append(tag)\n",
        "    fh.close()\n",
        "    return myoutput"
      ],
      "metadata": {
        "id": "sH2w1rM2Jd0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=load__data_conll(\"/content/drive/MyDrive/Restaurants_Train_v2_mod.iob\")\n",
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8rD0bFeKCDU",
        "outputId": "3ca18068-f087-4d1d-8a8e-b354b243cce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['But', 'the', 'staff', 'was', 'so', 'horrible', 'to', 'us'],\n",
              " ['O', 'O', 'B-A', 'O', 'O', 'O', 'O', 'O']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature engineering\n",
        "\n",
        "\n",
        "1.   **sent2feats(sentence)**.\n",
        "\n",
        "     Get features for all words in the sentence Features:\n",
        "\n",
        " *   word context: a window of 2 words on either side of the current word, and current word.\n",
        " *   POS context: a window of 2 POS tags on either side of the current word, and current tag. \n",
        " *   input: sentence as a list of tokens.\n",
        " *   output: list of dictionaries. each dict represents features for that word.\n",
        "\n",
        "2. **get_feats_conll(IOB_data)**\n",
        "\n",
        "  Extract features from the IOB data, after loading it.\n",
        "\n"
      ],
      "metadata": {
        "id": "mfO7QGIebX8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent2feats(sentence):\n",
        "    feats = []\n",
        "    sen_tags = pos_tag(sentence) #This format is specific to this POS tagger!\n",
        "    for i in range(0,len(sentence)):\n",
        "        word = sentence[i]\n",
        "        wordfeats = {}\n",
        "       #word features: word, prev 2 words, next 2 words in the sentence.\n",
        "        wordfeats['word'] = word\n",
        "        if i == 0:\n",
        "            wordfeats[\"prevWord\"] = wordfeats[\"prevSecondWord\"] = \"<S>\"\n",
        "        elif i==1:\n",
        "            wordfeats[\"prevWord\"] = sentence[0]\n",
        "            wordfeats[\"prevSecondWord\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"prevWord\"] = sentence[i-1]\n",
        "            wordfeats[\"prevSecondWord\"] = sentence[i-2]\n",
        "        #next two words as features\n",
        "        if i == len(sentence)-2:\n",
        "            wordfeats[\"nextWord\"] = sentence[i+1]\n",
        "            wordfeats[\"nextNextWord\"] = \"</S>\"\n",
        "        elif i==len(sentence)-1:\n",
        "            wordfeats[\"nextWord\"] = \"</S>\"\n",
        "            wordfeats[\"nextNextWord\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"nextWord\"] = sentence[i+1]\n",
        "            wordfeats[\"nextNextWord\"] = sentence[i+2]\n",
        "        \n",
        "        #POS tag features: current tag, previous and next 2 tags.\n",
        "        wordfeats['tag'] = sen_tags[i][1]\n",
        "        if i == 0:\n",
        "            wordfeats[\"prevTag\"] = wordfeats[\"prevSecondTag\"] = \"<S>\"\n",
        "        elif i == 1:\n",
        "            wordfeats[\"prevTag\"] = sen_tags[0][1]\n",
        "            wordfeats[\"prevSecondTag\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"prevTag\"] = sen_tags[i - 1][1]\n",
        "\n",
        "            wordfeats[\"prevSecondTag\"] = sen_tags[i - 2][1]\n",
        "            # next two words as features\n",
        "        if i == len(sentence) - 2:\n",
        "            wordfeats[\"nextTag\"] = sen_tags[i + 1][1]\n",
        "            wordfeats[\"nextNextTag\"] = \"</S>\"\n",
        "        elif i == len(sentence) - 1:\n",
        "            wordfeats[\"nextTag\"] = \"</S>\"\n",
        "            wordfeats[\"nextNextTag\"] = \"</S>\"\n",
        "        else:\n",
        "            wordfeats[\"nextTag\"] = sen_tags[i + 1][1]\n",
        "            wordfeats[\"nextNextTag\"] = sen_tags[i + 2][1]\n",
        "        #That is it! You can add whatever you want!\n",
        "        feats.append(wordfeats)\n",
        "    return feats"
      ],
      "metadata": {
        "id": "M5Ttsl5aJd37"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent2feats(data[0][0][0:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msFfXc3aPI5q",
        "outputId": "002ace68-092f-4617-b07a-ecb3387c8010"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'nextNextTag': '</S>',\n",
              "  'nextNextWord': '</S>',\n",
              "  'nextTag': '</S>',\n",
              "  'nextWord': '</S>',\n",
              "  'prevSecondTag': '<S>',\n",
              "  'prevSecondWord': '<S>',\n",
              "  'prevTag': '<S>',\n",
              "  'prevWord': '<S>',\n",
              "  'tag': 'CC',\n",
              "  'word': 'But'}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feats_conll(IOB_data):\n",
        "    feats = []\n",
        "    labels = []\n",
        "    for sentence in IOB_data:\n",
        "        feats.append(sent2feats(sentence[0]))\n",
        "        labels.append(sentence[1])\n",
        "    return feats, labels"
      ],
      "metadata": {
        "id": "Am6-dX00Jd5t"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a sequence model\n",
        "1. **train_seq(X_train,Y_train,X_dev,Y_dev)**\n",
        "   * CRF Model Training.\n",
        "2. **print_cm(cm, labels)**\n",
        "   * pretty print for confusion matrixes.\n",
        "3. **get_confusion_matrix(y_true,y_pred,labels)**\n",
        "   * python-crfsuite does not have a confusion matrix function, so writing it using sklearn's confusion matrix and print_cm from github."
      ],
      "metadata": {
        "id": "dgszMuGgdpx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_seq(X_train,Y_train,X_dev,Y_dev):\n",
        "    crf = CRF(algorithm='lbfgs', c1=0.1, c2=10, max_iterations=100, all_possible_states=True)\n",
        "    #Just to fit on training data\n",
        "    crf.fit(X_train, Y_train)\n",
        "    labels = list(crf.classes_)\n",
        "    #testing:\n",
        "    y_pred = crf.predict(X_dev)\n",
        "    sorted_labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
        "    print(f1_score(Y_dev, y_pred))\n",
        "    print(classification_report(Y_dev, y_pred))\n",
        "    get_confusion_matrix(Y_dev, y_pred,labels=sorted_labels) \n",
        "    return Y_dev,y_pred,sorted_labels"
      ],
      "metadata": {
        "id": "XkDRgNHEJd8w"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_cm(cm, labels):\n",
        "    print(\"\\n\")\n",
        "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
        "    empty_cell = \" \" * columnwidth\n",
        "    # Print header\n",
        "    print(\"    \" + empty_cell, end=\" \")\n",
        "    for label in labels:\n",
        "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
        "    print()\n",
        "    # Print rows\n",
        "    for i, label1 in enumerate(labels):\n",
        "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
        "        sum = 0\n",
        "        for j in range(len(labels)):\n",
        "            cell = \"%{0}.0f\".format(columnwidth) % cm[i, j]\n",
        "            sum =  sum + int(cell)\n",
        "            print(cell, end=\" \") \n",
        "        print(sum) #Prints the total number of instances per cat at the end."
      ],
      "metadata": {
        "id": "pIVRUgCRJd-n"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#python-crfsuite does not have a confusion matrix function, \n",
        "#so writing it using sklearn's confusion matrix and print_cm from github\n",
        "def get_confusion_matrix(y_true,y_pred,labels):\n",
        "    trues,preds = [], []\n",
        "    for yseq_true, yseq_pred in zip(y_true, y_pred):\n",
        "        trues.extend(yseq_true)\n",
        "        preds.extend(yseq_pred)\n",
        "    print_cm(confusion_matrix(trues,preds,labels=labels),labels) "
      ],
      "metadata": {
        "id": "T1uMtJuQJeB1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "* **main() function** to start training a sequential classification model with CRF."
      ],
      "metadata": {
        "id": "qug49WfyeyPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  \n",
        "    train_path = '/content/drive/MyDrive/Restaurants_Train_v2_mod.iob'\n",
        "    test_path = '/content/drive/MyDrive/Restaurants_Test_Gold_mod.iob'\n",
        "        \n",
        "    conll_train = load__data_conll(train_path)\n",
        "    conll_dev = load__data_conll(test_path)\n",
        "    \n",
        "    print(\"Training a Sequence classification model with CRF\")\n",
        "    feats, labels = get_feats_conll(conll_train)\n",
        "    #print(feats)\n",
        "    devfeats, devlabels = get_feats_conll(conll_dev)\n",
        "    global Y_dev,y_pred,sorted_labels\n",
        "    Y_dev,y_pred,sorted_labels=train_seq(feats, labels, devfeats, devlabels)\n",
        "    print(\"Done with sequence model\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main() "
      ],
      "metadata": {
        "id": "-LGhSZh5JeDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5daab22-0b6b-4208-8d05-831e5c3a7733"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training a Sequence classification model with CRF\n",
            "0.6358754027926959\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.81      0.52      0.64      1134\n",
            "\n",
            "   micro avg       0.81      0.52      0.64      1134\n",
            "   macro avg       0.81      0.52      0.64      1134\n",
            "weighted avg       0.81      0.52      0.64      1134\n",
            "\n",
            "\n",
            "\n",
            "              O   B-A   I-A \n",
            "        O  9190    59    30 9279\n",
            "      B-A   479   624    31 1134\n",
            "      I-A   257    45   198 500\n",
            "Done with sequence model\n"
          ]
        }
      ]
    }
  ]
}